{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33cd9fb-6930-464b-ac93-b372c4cc720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\monster\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\monster\\anaconda3\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\monster\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\monster\\anaconda3\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\monster\\anaconda3\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\monster\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\monster\\anaconda3\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\monster\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\monster\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: click in c:\\users\\monster\\anaconda3\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from nltk) (2025.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\monster\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\monster\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\monster\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Kullanılan cihaz: cpu\n",
      "Stopwords indiriliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Monster\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri yükleniyor...\n",
      "Toplam yorum: 50000\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio pandas numpy scikit-learn matplotlib seaborn nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# GPU Kontrolü\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kullanılan cihaz: {device}\")\n",
    "\n",
    "# Stopwords indirme\n",
    "print(\"Stopwords indiriliyor...\")\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Veriyi Yükle\n",
    "print(\"Veri yükleniyor...\")\n",
    "imdb_data = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "print(f\"Toplam yorum: {len(imdb_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7142f99f-eae8-477c-891b-909574e0590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veriler temizleniyor...\n",
      "Eğitim Seti: 40000\n",
      "Test Seti: 10000\n"
     ]
    }
   ],
   "source": [
    "# Temizleme Fonksiyonu\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "print(\"Veriler temizleniyor...\")\n",
    "imdb_data['cleaned_review'] = imdb_data['review'].apply(clean_text)\n",
    "imdb_data['label'] = imdb_data['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Train/Test Split (random_state = 42)\n",
    "X = imdb_data['cleaned_review']\n",
    "y = imdb_data['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Eğitim Seti: {len(X_train)}\")\n",
    "print(f\"Test Seti: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dd82eb-2e35-43fb-b145-21480691be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sözlük ve diziler oluşturuluyor...\n",
      "Vocabulary Boyutu: 20001\n",
      "Stopwords Kümesi: 198 kelime\n",
      "\n",
      "En Sık Kullanılan 10 Kelime:\n",
      "  movie: 66900\n",
      "  film: 59913\n",
      "  one: 40389\n",
      "  like: 30923\n",
      "  good: 22828\n",
      "  even: 19365\n",
      "  would: 19238\n",
      "  time: 18641\n",
      "  really: 18383\n",
      "  see: 17986\n",
      "\n",
      "Eğitim Seti Dizi Sayısı: 40000\n",
      "Test Seti Dizi Sayısı: 10000\n",
      "\n",
      "Örnek Yorum Metni: i caught this little gem totally by accident back in or i was at a revival theatre to see two old si\n",
      "Örnek Yorumun Sayı Hali: [896, 39, 1343, 328, 1478, 53, 8350, 1497, 10, 32, 75, 538, 763, 21, 1497]\n"
     ]
    }
   ],
   "source": [
    "# SÖZLÜK VE TOKENIZATION FONKSİYONU\n",
    "def build_vocab_and_sequences(texts, max_words=20000):\n",
    "    word_freq = {}\n",
    "    # Kelime Sayımı\n",
    "    for text in texts:\n",
    "        for word in text.split():\n",
    "            if word not in stop_words:\n",
    "                word_freq[word] = word_freq.get(word, 0) + 1\n",
    "    \n",
    "    # Sıralama ve En Sık Geçenleri Seçme\n",
    "    # sorted_words'ü hesaplıyoruz ve return ile dışarı atıyoruz\n",
    "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:max_words]\n",
    "    \n",
    "    vocab = {word: i+1 for i, (word, count) in enumerate(sorted_words)}\n",
    "    vocab['<UNK>'] = len(vocab) + 1 # Bilinmeyen kelimeler için\n",
    "    \n",
    "    # Metinleri Sayı Dizisine Çevirme (Tokenization)\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        seq = [vocab.get(word, vocab['<UNK>']) for word in text.split() if word in vocab or word == '<UNK>']\n",
    "        sequences.append(seq)\n",
    "        \n",
    "    # Fonksiyon artık sorted_words listesini de döndürüyor\n",
    "    return vocab, sequences, sorted_words\n",
    "\n",
    "print(\"Sözlük ve diziler oluşturuluyor...\")\n",
    "\n",
    "# Train seti üzerinden sözlük oluşturuluyor \n",
    "vocab, X_train_seq, sorted_words = build_vocab_and_sequences(X_train, max_words=20000)\n",
    "\n",
    "# Test seti aynı sözlükle dönüştürülüyor\n",
    "X_test_seq = []\n",
    "for text in X_test:\n",
    "    seq = [vocab.get(word, vocab['<UNK>']) for word in text.split() if word in vocab]\n",
    "    X_test_seq.append(seq)\n",
    "\n",
    "print(f\"Vocabulary Boyutu: {len(vocab)}\")\n",
    "print(f\"Stopwords Kümesi: {len(stop_words)} kelime\")\n",
    "print(f\"\\nEn Sık Kullanılan 10 Kelime:\")\n",
    "for word, freq in sorted_words[:10]:\n",
    "    print(f\"  {word}: {freq}\")\n",
    "print(f\"\\nEğitim Seti Dizi Sayısı: {len(X_train_seq)}\")\n",
    "print(f\"Test Seti Dizi Sayısı: {len(X_test_seq)}\")\n",
    "print(f\"\\nÖrnek Yorum Metni: {X_train.iloc[0][:100]}\")\n",
    "print(f\"Örnek Yorumun Sayı Hali: {X_train_seq[0][:15]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd054fd-85aa-4120-a32b-7de4f5a96ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train verisi şekli: (40000, 256)\n",
      "Test verisi şekli: (10000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Padding\n",
    "# Bu fonksiyon, farklı uzunluktaki yorumları alıp hepsini aynı boyut getirir. Eksik kısımları 0 ile doldurur.\n",
    "def pad_sequences_manual(sequences, max_len=256):\n",
    "    features = np.zeros((len(sequences), max_len), dtype=int)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if len(seq) != 0:\n",
    "            features[i, -len(seq):] = np.array(seq)[:max_len]\n",
    "    return features\n",
    "    \n",
    "# Fonksiyonu Eğitim ve Test verilerine uyguluyoruz\n",
    "# Her yorumu kelime uzunluğuna sabitliyoruz.\n",
    "X_train_padded = pad_sequences_manual(X_train_seq, max_len=256)\n",
    "X_test_padded = pad_sequences_manual(X_test_seq, max_len=256)\n",
    "\n",
    "print(f\"Train verisi şekli: {X_train_padded.shape}\")\n",
    "print(f\"Test verisi şekli: {X_test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b52a39-55ee-4745-a419-87bffcc20f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size: 64\n",
      "Train Loader Adım Sayısı: 625\n",
      "Test Loader Adım Sayısı: 157\n"
     ]
    }
   ],
   "source": [
    "# Eğitim ve test verilini Tensor'a çevir\n",
    "train_data = TensorDataset(torch.from_numpy(X_train_padded), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test_padded), torch.from_numpy(y_test))\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 64 # Model her adımda 64 tane yorumu aynı anda okuyacak.\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"Train Loader Adım Sayısı: {len(train_loader)}\")\n",
    "print(f\"Test Loader Adım Sayısı: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415aad5e-5458-452e-9c39-249503987dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeller başarıyla tanımlandı.\n"
     ]
    }
   ],
   "source": [
    "# 1. Model: LSTM (Hafızalı Sinir Ağı)\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds)\n",
    "        lstm_out = lstm_out[:, -1, :] \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "# 2. Model: CNN (Metin İçin Konvolüsyonel Ağ)\n",
    "class SentimentCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim):\n",
    "        super(SentimentCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Farklı boyutlarda filtreler (3'lü, 4'lü, 5'li kelime gruplarını yakalar)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 100, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(embedding_dim, 100, kernel_size=4)\n",
    "        self.conv3 = nn.Conv1d(embedding_dim, 100, kernel_size=5)\n",
    "        \n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(300, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1) # Boyut değişimi (Batch, Embed, Seq)\n",
    "        \n",
    "        x1 = self.pool(torch.relu(self.conv1(x))).squeeze(-1)\n",
    "        x2 = self.pool(torch.relu(self.conv2(x))).squeeze(-1)\n",
    "        x3 = self.pool(torch.relu(self.conv3(x))).squeeze(-1)\n",
    "        \n",
    "        x_concat = torch.cat((x1, x2, x3), dim=1)\n",
    "        out = self.dropout(x_concat)\n",
    "        out = self.fc(out)\n",
    "        return self.sigmoid(out)\n",
    "        \n",
    "print(\"Modeller başarıyla tanımlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce620313-a9c2-43ff-94cb-4717364d3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim Fonksiyonu \n",
    "def train_model(model, train_loader, epochs=1, lr=0.001):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"--- {type(model).__name__} Eğitiliyor... ---\")\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device).long(), labels.to(device).float()\n",
    "            model.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1} Tamamlandı. Loss: {train_loss/len(train_loader):.4f}\")\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322d0989-f87b-476a-b7dc-e5ed48812d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin Fonksiyonu\n",
    "def get_predictions(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in loader:\n",
    "            inputs = inputs.to(device).long()\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.round(outputs.squeeze()).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "    return np.array(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee3c36d-69e8-49c1-9b8c-15ccbf83de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LSTM EĞİTİMİ ---\n",
      "--- SentimentLSTM Eğitiliyor... ---\n",
      "Epoch 1 Tamamlandı. Loss: 0.6510\n",
      "Epoch 2 Tamamlandı. Loss: 0.5732\n",
      "Epoch 3 Tamamlandı. Loss: 0.3137\n",
      "\n",
      "--- CNN EĞİTİMİ ---\n",
      "--- SentimentCNN Eğitiliyor... ---\n",
      "Epoch 1 Tamamlandı. Loss: 0.5694\n",
      "Epoch 2 Tamamlandı. Loss: 0.4031\n",
      "Epoch 3 Tamamlandı. Loss: 0.3245\n",
      "\n",
      "Eğitimler tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab) + 2 # Pad ve Unk için\n",
    "\n",
    "# LSTM Hiperparametreleri ve Eğitim\n",
    "print(\"\\n--- LSTM EĞİTİMİ ---\")\n",
    "model_lstm = SentimentLSTM(vocab_size, output_size=1, embedding_dim=100, hidden_dim=256, n_layers=2)\n",
    "model_lstm = train_model(model_lstm, train_loader, epochs=3, lr=0.001)\n",
    "\n",
    "# CNN Hiperparametreleri ve Eğitim\n",
    "print(\"\\n--- CNN EĞİTİMİ ---\")\n",
    "model_cnn = SentimentCNN(vocab_size, output_size=1, embedding_dim=100)\n",
    "model_cnn = train_model(model_cnn, train_loader, epochs=3, lr=0.001)\n",
    "\n",
    "print(\"\\nEğitimler tamamlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0844b88b-04d5-40fb-8015-3d28fb0aab2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GENEL MODEL KARŞILAŞTIRMASI ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7327a_row0_col0, #T_7327a_row0_col2, #T_7327a_row2_col0, #T_7327a_row2_col1, #T_7327a_row2_col3 {\n",
       "  font-weight: bold;\n",
       "  background-color: #90ee90;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7327a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7327a_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_7327a_level0_col1\" class=\"col_heading level0 col1\" >F1 Score (Weighted)</th>\n",
       "      <th id=\"T_7327a_level0_col2\" class=\"col_heading level0 col2\" >Precision (Weighted)</th>\n",
       "      <th id=\"T_7327a_level0_col3\" class=\"col_heading level0 col3\" >Recall (Weighted)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7327a_level0_row0\" class=\"row_heading level0 row0\" >LSTM</th>\n",
       "      <td id=\"T_7327a_row0_col0\" class=\"data row0 col0\" >0.879800</td>\n",
       "      <td id=\"T_7327a_row0_col1\" class=\"data row0 col1\" >0.879799</td>\n",
       "      <td id=\"T_7327a_row0_col2\" class=\"data row0 col2\" >0.879814</td>\n",
       "      <td id=\"T_7327a_row0_col3\" class=\"data row0 col3\" >0.879800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7327a_level0_row1\" class=\"row_heading level0 row1\" >CNN</th>\n",
       "      <td id=\"T_7327a_row1_col0\" class=\"data row1 col0\" >0.874100</td>\n",
       "      <td id=\"T_7327a_row1_col1\" class=\"data row1 col1\" >0.874035</td>\n",
       "      <td id=\"T_7327a_row1_col2\" class=\"data row1 col2\" >0.874873</td>\n",
       "      <td id=\"T_7327a_row1_col3\" class=\"data row1 col3\" >0.874100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7327a_level0_row2\" class=\"row_heading level0 row2\" >Logistic Regression</th>\n",
       "      <td id=\"T_7327a_row2_col0\" class=\"data row2 col0\" >0.879800</td>\n",
       "      <td id=\"T_7327a_row2_col1\" class=\"data row2 col1\" >0.880800</td>\n",
       "      <td id=\"T_7327a_row2_col2\" class=\"data row2 col2\" >0.873500</td>\n",
       "      <td id=\"T_7327a_row2_col3\" class=\"data row2 col3\" >0.888200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27b4c3e2210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tahminleri al\n",
    "y_pred_lstm = get_predictions(model_lstm, test_loader)\n",
    "y_pred_cnn = get_predictions(model_cnn, test_loader)\n",
    "\n",
    "def get_summary_metrics(y_true, y_pred, model_name):\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'F1 Score (Weighted)': f1_score(y_true, y_pred, average='weighted'),\n",
    "        'Precision (Weighted)': precision_score(y_true, y_pred, average='weighted'),\n",
    "        'Recall (Weighted)': recall_score(y_true, y_pred, average='weighted')\n",
    "    }\n",
    "\n",
    "metrics_lstm = get_summary_metrics(y_test, y_pred_lstm, 'LSTM')\n",
    "metrics_cnn = get_summary_metrics(y_test, y_pred_cnn, 'CNN')\n",
    "# Önceki projeden alınan logistic regression model metrik değerleri\n",
    "metrics_log = {'Model': 'Logistic Regression',\n",
    "               'Accuracy': 0.8798,\n",
    "               'F1 Score (Weighted)': 0.8808,\n",
    "               'Precision (Weighted)': 0.8735,\n",
    "               'Recall (Weighted)': 0.8882}\n",
    "\n",
    "df_general = pd.DataFrame([metrics_lstm, metrics_cnn, metrics_log]).set_index('Model')\n",
    "\n",
    "def highlight_max_gen(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold; background-color: #90ee90' if v else '' for v in is_max]\n",
    "\n",
    "print(\"\\n=== GENEL MODEL KARŞILAŞTIRMASI ===\")\n",
    "display(df_general.style.apply(highlight_max_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc603ddb-4f7b-466b-8c43-1eeb649e9fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SINIF BAZLI BAŞARIM ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_59b41_row0_col0, #T_59b41_row0_col1, #T_59b41_row1_col0, #T_59b41_row1_col2, #T_59b41_row2_col1, #T_59b41_row2_col2 {\n",
       "  background-color: #e0e0e0;\n",
       "  color: black;\n",
       "}\n",
       "#T_59b41_row0_col2, #T_59b41_row1_col1, #T_59b41_row2_col0 {\n",
       "  background-color: #e0e0e0;\n",
       "  color: black;\n",
       "  background-color: #90ee90;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_59b41_row3_col0, #T_59b41_row3_col1, #T_59b41_row3_col2, #T_59b41_row4_col1, #T_59b41_row4_col2, #T_59b41_row5_col0 {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "}\n",
       "#T_59b41_row4_col0, #T_59b41_row5_col1, #T_59b41_row5_col2 {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "  background-color: #90ee90;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_59b41\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_59b41_level0_col0\" class=\"col_heading level0 col0\" >Precision</th>\n",
       "      <th id=\"T_59b41_level0_col1\" class=\"col_heading level0 col1\" >Recall</th>\n",
       "      <th id=\"T_59b41_level0_col2\" class=\"col_heading level0 col2\" >F1-Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Sınıf</th>\n",
       "      <th class=\"index_name level1\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_59b41_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">Negative</th>\n",
       "      <th id=\"T_59b41_level1_row0\" class=\"row_heading level1 row0\" >LSTM</th>\n",
       "      <td id=\"T_59b41_row0_col0\" class=\"data row0 col0\" >0.882093</td>\n",
       "      <td id=\"T_59b41_row0_col1\" class=\"data row0 col1\" >0.876800</td>\n",
       "      <td id=\"T_59b41_row0_col2\" class=\"data row0 col2\" >0.879438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59b41_level1_row1\" class=\"row_heading level1 row1\" >CNN</th>\n",
       "      <td id=\"T_59b41_row1_col0\" class=\"data row1 col0\" >0.857853</td>\n",
       "      <td id=\"T_59b41_row1_col1\" class=\"data row1 col1\" >0.896800</td>\n",
       "      <td id=\"T_59b41_row1_col2\" class=\"data row1 col2\" >0.876894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59b41_level1_row2\" class=\"row_heading level1 row2\" >Log Reg</th>\n",
       "      <td id=\"T_59b41_row2_col0\" class=\"data row2 col0\" >0.886289</td>\n",
       "      <td id=\"T_59b41_row2_col1\" class=\"data row2 col1\" >0.871400</td>\n",
       "      <td id=\"T_59b41_row2_col2\" class=\"data row2 col2\" >0.878781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59b41_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"3\">Positive</th>\n",
       "      <th id=\"T_59b41_level1_row3\" class=\"row_heading level1 row3\" >LSTM</th>\n",
       "      <td id=\"T_59b41_row3_col0\" class=\"data row3 col0\" >0.877535</td>\n",
       "      <td id=\"T_59b41_row3_col1\" class=\"data row3 col1\" >0.882800</td>\n",
       "      <td id=\"T_59b41_row3_col2\" class=\"data row3 col2\" >0.880160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59b41_level1_row4\" class=\"row_heading level1 row4\" >CNN</th>\n",
       "      <td id=\"T_59b41_row4_col0\" class=\"data row4 col0\" >0.891892</td>\n",
       "      <td id=\"T_59b41_row4_col1\" class=\"data row4 col1\" >0.851400</td>\n",
       "      <td id=\"T_59b41_row4_col2\" class=\"data row4 col2\" >0.871176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59b41_level1_row5\" class=\"row_heading level1 row5\" >Log Reg</th>\n",
       "      <td id=\"T_59b41_row5_col0\" class=\"data row5 col0\" >0.873524</td>\n",
       "      <td id=\"T_59b41_row5_col1\" class=\"data row5 col1\" >0.888200</td>\n",
       "      <td id=\"T_59b41_row5_col2\" class=\"data row5 col2\" >0.880801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27b4c3e2210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EN İYİ MODEL: LSTM (%87.98)\n"
     ]
    }
   ],
   "source": [
    "report_lstm = classification_report(y_test, y_pred_lstm, output_dict=True)\n",
    "report_cnn = classification_report(y_test, y_pred_cnn, output_dict=True)\n",
    "\n",
    "# Önceki projeden alınan Lojistik Regresyon metrik değerleri\n",
    "log_reg_data = {\n",
    "    'Negative': {'p': 0.886289, 'r': 0.871400, 'f1': 0.878781},\n",
    "    'Positive': {'p': 0.873524, 'r': 0.888200, 'f1': 0.880801}\n",
    "}\n",
    "\n",
    "class_metrics = []\n",
    "classes = {'0': 'Negative', '1': 'Positive'}\n",
    "\n",
    "for cls_key, cls_name in classes.items():\n",
    "    \n",
    "    class_metrics.append({'Sınıf': cls_name, 'Model': 'LSTM', \n",
    "                          'Precision': report_lstm[cls_key]['precision'], \n",
    "                          'Recall': report_lstm[cls_key]['recall'], \n",
    "                          'F1-Score': report_lstm[cls_key]['f1-score']})\n",
    "    \n",
    "    class_metrics.append({'Sınıf': cls_name, 'Model': 'CNN', \n",
    "                          'Precision': report_cnn[cls_key]['precision'], \n",
    "                          'Recall': report_cnn[cls_key]['recall'], \n",
    "                          'F1-Score': report_cnn[cls_key]['f1-score']})\n",
    "    \n",
    "    class_metrics.append({'Sınıf': cls_name, 'Model': 'Log Reg', \n",
    "                          'Precision': log_reg_data[cls_name]['p'], \n",
    "                          'Recall': log_reg_data[cls_name]['r'], \n",
    "                          'F1-Score': log_reg_data[cls_name]['f1']})\n",
    "\n",
    "df_class_based = pd.DataFrame(class_metrics).set_index(['Sınıf', 'Model'])\n",
    "\n",
    "\n",
    "def custom_style(df):\n",
    "    styles = pd.DataFrame('', index=df.index, columns=df.columns)\n",
    "    for idx in df.index:\n",
    "        if idx[0] == 'Negative':\n",
    "            styles.loc[idx, :] = 'background-color: #e0e0e0; color: black' # Gri\n",
    "        else:\n",
    "            styles.loc[idx, :] = 'background-color: white; color: black' # Beyaz\n",
    "\n",
    "    # En Yüksek Değerleri Yeşil Yapma (Grup Bazlı)\n",
    "    for col in df.columns:\n",
    "        # Negative Grubu için Max\n",
    "        max_neg = df.loc['Negative', col].max()\n",
    "        # Positive Grubu için Max\n",
    "        max_pos = df.loc['Positive', col].max()\n",
    "        for idx in df.index:\n",
    "            val = df.loc[idx, col]\n",
    "            if idx[0] == 'Negative' and val == max_neg:\n",
    "                styles.loc[idx, col] += '; background-color: #90ee90; font-weight: bold' # Açık Yeşil\n",
    "            elif idx[0] == 'Positive' and val == max_pos:\n",
    "                styles.loc[idx, col] += '; background-color: #90ee90; font-weight: bold' # Açık Yeşil      \n",
    "    return styles\n",
    "\n",
    "print(\"\\n=== SINIF BAZLI BAŞARIM ===\")\n",
    "# style.apply(..., axis=None) tüm tabloyu fonksiyona gönderir\n",
    "display(df_class_based.style.apply(custom_style, axis=None))\n",
    "\n",
    "best_model = df_general['Accuracy'].idxmax()\n",
    "best_acc = df_general['Accuracy'].max()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"EN İYİ MODEL: {best_model} (%{best_acc*100:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
